<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<meta name="generator" content="Hugo 0.50" />
	<meta property="og:title" content="What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?" />
<meta property="og:description" content="Recently, during a discussion with a colleague about his CNN model architecture on remote sensing image fusion task, he mentioned something that was interesting. Specifically, in his network, he used FCN implementations Keras.layers.Dense and torch.nn.Linear in his code, the input to the FCN is a 2D image with many channels with size (160, 160, channels). Traditionally, I think that to pass through a FCN layer, the neuron numbers of the first FCN layer in this case, should be 160 * 160 * channels, which basically means to flat the volume to a 1D array and feed in a traditional neural network." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhiqiyu.github.io/post/what-are-fully-connected-layers-fcn-in-convolutional-neural-networks-cnn/" /><meta property="article:published_time" content="2018-11-08T11:24:36-05:00"/>
<meta property="article:modified_time" content="2018-11-08T11:24:36-05:00"/>

	<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?"/>
<meta name="twitter:description" content="Recently, during a discussion with a colleague about his CNN model architecture on remote sensing image fusion task, he mentioned something that was interesting. Specifically, in his network, he used FCN implementations Keras.layers.Dense and torch.nn.Linear in his code, the input to the FCN is a 2D image with many channels with size (160, 160, channels). Traditionally, I think that to pass through a FCN layer, the neuron numbers of the first FCN layer in this case, should be 160 * 160 * channels, which basically means to flat the volume to a 1D array and feed in a traditional neural network."/>

	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="https://zhiqiyu.github.io/css/style.css">
	<link rel="shortcut icon" href="https://zhiqiyu.github.io/img/favicon-96.png">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-128672710-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<link rel="stylesheet" href="https://zhiqiyu.github.io/css/xcode.css" rel="stylesheet" id="theme-stylesheet">
	<script src="https://zhiqiyu.github.io/js/highlight.pack.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>

	<div class="container">
		<div class="logo" role="banner">
			<a class="logo__link" href="https://zhiqiyu.github.io/" title="ZQ.Yu" rel="home">
				<div class="logo__title">ZQ.Yu</div>
				<div class="logo__tagline">Geospatial data explorer, Machine learning enthusiast</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="https://zhiqiyu.github.io/">Blog</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="https://zhiqiyu.github.io/about/">About</a>
		</li>
	</ul>
</nav>

	</div>

	<script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://zhiqiyu.github.io/"
    },
    "articleSection" : "post",
    "name" : "What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?",
    "headline" : "What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?",
    "description" : "Recently, during a discussion with a colleague about his CNN model architecture on remote sensing image fusion task, he mentioned something that was interesting. Specifically, in his network, he used FCN implementations Keras.layers.Dense and torch.nn.Linear in his code, the input to the FCN is a 2D image with many channels with size (160, 160, channels). Traditionally, I think that to pass through a FCN layer, the neuron numbers of the first FCN layer in this case, should be 160 * 160 * channels, which basically means to flat the volume to a 1D array and feed in a traditional neural network.",
    "inLanguage" : "en-US",
    "author" : "img/avatar.jpgPh.D. student in Geoinformation ScienceZhiqi Yu",
    "creator" : "img/avatar.jpgPh.D. student in Geoinformation ScienceZhiqi Yu",
    "publisher": "img/avatar.jpgPh.D. student in Geoinformation ScienceZhiqi Yu",
    "accountablePerson" : "img/avatar.jpgPh.D. student in Geoinformation ScienceZhiqi Yu",
    "copyrightHolder" : "img/avatar.jpgPh.D. student in Geoinformation ScienceZhiqi Yu",
    "copyrightYear" : "2018",
    "datePublished": "2018-11-08 11:24:36 -0500 EST",
    "dateModified" : "2018-11-08 11:24:36 -0500 EST",
    "url" : "https://zhiqiyu.github.io/post/what-are-fully-connected-layers-fcn-in-convolutional-neural-networks-cnn/",
    "wordCount" : "760",
    "keywords" : [ "Deep Learning","Keras","Blog" ]
}
</script>
</header>
		<div class="wrapper flex">
			<section class="primary">
			
<main class="main" role="main">
	<article class="post">
		
		<header class="post__header">
			<h1 class="post__title">What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 16 16"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
	<time class="meta__text" datetime="2018-11-08T11:24:36">November 08, 2018</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="https://zhiqiyu.github.io/categories/technical" rel="category">Technical</a></span>
</div>
</div>
		
		</header><div class="content post__content clearfix">
			

<p>Recently, during a discussion with a colleague about his CNN model architecture on remote sensing image fusion task, he mentioned something that was interesting. Specifically, in his network, he used FCN implementations <code>Keras.layers.Dense</code> and <code>torch.nn.Linear</code> in his code, the input to the FCN is a 2D image with many channels with size <code>(160, 160, channels)</code>. Traditionally, I think that to pass through a FCN layer, the neuron numbers of the first FCN layer in this case, should be <code>160 * 160 * channels</code>, which basically means to flat the volume to a 1D array and feed in a traditional neural network. Therefore, I argued that his network should be really hard to train because with such large number of neurons in a layer, the whole FCN should have millions of parameters. Just like the VGG, the parameters of its FCN layers are:</p>

<table>
<thead>
<tr>
<th align="left">layer #</th>
<th align="left">parameters</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">1</td>
<td align="left">7*7*512*4096 + 4096 = 102,764,544</td>
</tr>

<tr>
<td align="left">2</td>
<td align="left">4096*4096 + 4096 = 16,781,312</td>
</tr>

<tr>
<td align="left">3</td>
<td align="left">4096*1000 + 1000 = 4,097,000</td>
</tr>

<tr>
<td align="left"><strong>Total</strong></td>
<td align="left">approx. <strong>123.64M</strong></td>
</tr>
</tbody>
</table>

<p>However, my colleague told me that his FCN does not have such large number of parameters. Specifically, in his code, he used <code>Dense(channel#1)</code> and <code>Dense(channel#2)</code> instead of <code>Dense(160*160*channel#1)</code> and <code>Dense(160*160*channel#2)</code>. Therefore, his network only has <code>channel#1 * channel#2</code> parameters, which is signifiantly less than <code>160*160*160*160*channel#1 * channel#2</code>. This makes me wonder what dense layers are actually computing.</p>

<p>By digging around on the internet, I found a quote by Yan LeCuns:</p>

<blockquote>
<p>In Convolutional Nets, there is no such thing as &ldquo;fully-connected layers&rdquo;. There are only convolution layers with 1x1 convolution kernels and a full connection table.</p>

<p>It&rsquo;s a too-rarely-understood fact that ConvNets don&rsquo;t need to have a fixed-size input. You can train them on inputs that happen to produce a single output vector (with no spatial extent), and then apply them to larger images. Instead of a single output vector, you then get a spatial map of output vectors. Each vector sees input windows at different locations on the input.</p>

<p>In that scenario, the &ldquo;fully connected layers&rdquo; really act as 1x1 convolutions.</p>
</blockquote>

<p>This quote is not very explicit, but what LeCuns tries to say is that in CNN, if the input to the FCN is a volume instead of a vector, the FCN really acts as 1x1 convolutions, which only do convolutions in the channel dimension and reserve the spatial extent. But this is not true in the VGG case. In VGG, the input to the FCN is a <code>7*7*512</code> volume, what the first FCN layer does is actually a 7x7 convolution that shrink the volume to a 1x1 vector, and then do 1x1 convolution on the vector.</p>

<p>To further explain what the dense layer does in CNN, let&rsquo;s see an example in Keras:</p>

<pre><code class="language-python">from keras.models import Sequential
from keras.layers import Dense, Activation
model = Sequential()
model.add(Dense(16, input_shape=(3,2)))
model.add(Activation('relu'))
model.add(Dense(4))
model.compile(loss='mean_squared_error', optimizer='SGD')
print(model.weights)
</code></pre>

<p>By running this example code, we can get the weights of the model as follows:</p>

<pre><code class="language-python">[&lt;tf.Variable 'dense_13/kernel:0' shape=(2, 16) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_13/bias:0' shape=(16,) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_14/kernel:0' shape=(16, 4) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_14/bias:0' shape=(4,) dtype=float32_ref&gt;]
</code></pre>

<p>In this example, the input tensor with size <code>(3, 2)</code> is passed through a dense layer with 16 neurons, and then thorugh another dense layer with 4 neurons. In traditional neural networks, we can easily think that the first layer has <code>3 * 2 * 16 = 96</code> parameters as each neuron is connected to <code>3x2 = 6</code> inputs, and the next layer has <code>16 * 4 = 64</code> parameters. <strong>However</strong>, we can see that the printed weight matrix size of the first dense layer is <code>(2, 16)</code>, not <code>(2*3, 16)</code>.</p>

<p>Let&rsquo;s see another example:</p>

<pre><code class="language-python">from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten
model = Sequential()
model.add(Flatten(input_shape=(3,2)))  # Flatten the input before feeding it into the dense layer
model.add(Dense(16))
model.add(Activation('relu'))
model.add(Dense(4))
model.compile(loss='mean_squared_error', optimizer='SGD')
print(model.weights)
</code></pre>

<p>This code snippet prints out:</p>

<pre><code class="language-python">[&lt;tf.Variable 'dense_15/kernel:0' shape=(6, 16) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_15/bias:0' shape=(16,) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_16/kernel:0' shape=(16, 4) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_16/bias:0' shape=(4,) dtype=float32_ref&gt;]
</code></pre>

<p>There we can see that by flattening the input to a 1-D array before feeding it to the dense layers, the weight matrix of the first layer becomes <code>(6, 16)</code>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>How the FCN in CNN really do depends on the input shape:</p>

<ul>
<li>If the input is a 1-D vector, such as the output of the first VGG FCN layer <code>(1x1, 4096)</code>, the dense layers are the same as the hidden layers in traditional neural networks (multi-layer perceptron).</li>
<li>If the input rank is higher than 1, for example, an image volume, the FCN layer in CNN is actually doing similar things as a 1x1 convolution operation on each pixel slice.</li>
</ul>

		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 16 16"><path d="M16 9.5c0 .373-.24.74-.5 1l-5 5c-.275.26-.634.5-1 .5-.373 0-.74-.24-1-.5L1 8a2.853 2.853 0 0 1-.7-1C.113 6.55 0 5.973 0 5.6V1.4C0 1.034.134.669.401.401.67.134 1.034 0 1.4 0h4.2c.373 0 .95.113 1.4.3.45.187.732.432 1 .7l7.5 7.502c.26.274.5.632.5.998zM3.5 5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="https://zhiqiyu.github.io/tags/deep-learning/" rel="tag">Deep Learning</a></li>
		<li class="tags__item"><a class="tags__link btn" href="https://zhiqiyu.github.io/tags/keras/" rel="tag">Keras</a></li>
	</ul>
</div>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Zhiqi Yu avatar" src="https://zhiqiyu.github.io/img/avatar.jpg" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Zhiqi Yu</span>
	</div>
	<div class="authorbox__description">
		Ph.D. student in Geoinformation Science
	</div>
</div>

<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="https://zhiqiyu.github.io/post/deep-learning-specialization-certificate/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Deep Learning Specialization Certificate</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="https://zhiqiyu.github.io/post/same-day-landsat-8-and-sentinel-2-pair-generation-on-gee/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Same-day Landsat-8 and Sentinel-2 Pair Generation on GEE</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "realm-z" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</section>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2019 Zhiqi Yu.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="https://zhiqiyu.github.io/js/menu.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>