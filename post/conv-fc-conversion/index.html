<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)? - ZQ.Yu</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?" />
<meta property="og:description" content="Recently, during a discussion with a colleague about his CNN model architecture on remote sensing image fusion task, he mentioned something that was interesting. Specifically, in his network, he used FCN implementations Keras.layers.Dense and torch.nn.Linear in his code, the input to the FCN is a 2D image with many channels with size (160, 160, channels). Traditionally, I think that to pass through a FCN layer, the neuron numbers of the first FCN layer in this case, should be 160 * 160 * channels, which basically means to flat the volume to a 1D array and feed in a traditional neural network." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhiqiyu.github.io/post/conv-fc-conversion/" />
<meta property="article:published_time" content="2018-11-08T11:24:36-05:00" />
<meta property="article:modified_time" content="2018-11-08T11:24:36-05:00" />

		<meta itemprop="name" content="What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?">
<meta itemprop="description" content="Recently, during a discussion with a colleague about his CNN model architecture on remote sensing image fusion task, he mentioned something that was interesting. Specifically, in his network, he used FCN implementations Keras.layers.Dense and torch.nn.Linear in his code, the input to the FCN is a 2D image with many channels with size (160, 160, channels). Traditionally, I think that to pass through a FCN layer, the neuron numbers of the first FCN layer in this case, should be 160 * 160 * channels, which basically means to flat the volume to a 1D array and feed in a traditional neural network.">
<meta itemprop="datePublished" content="2018-11-08T11:24:36-05:00" />
<meta itemprop="dateModified" content="2018-11-08T11:24:36-05:00" />
<meta itemprop="wordCount" content="760">



<meta itemprop="keywords" content="Deep Learning,Keras," />

		<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="What are Fully-Connected Layers (FCN) in Convolutional Neural Networks (CNN)?"/>
<meta name="twitter:description" content="Recently, during a discussion with a colleague about his CNN model architecture on remote sensing image fusion task, he mentioned something that was interesting. Specifically, in his network, he used FCN implementations Keras.layers.Dense and torch.nn.Linear in his code, the input to the FCN is a 2D image with many channels with size (160, 160, channels). Traditionally, I think that to pass through a FCN layer, the neuron numbers of the first FCN layer in this case, should be 160 * 160 * channels, which basically means to flat the volume to a 1D array and feed in a traditional neural network."/>

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="https://zhiqiyu.github.io/css/style.css">
	

	<link rel="shortcut icon" href="https://zhiqiyu.github.io/favicon.ico">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-128672710-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="https://zhiqiyu.github.io/" title="ZQ.Yu" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ZQ.Yu</div>
					<div class="logo__tagline">A place to share my work, study, achievements and life</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="https://zhiqiyu.github.io/">
				
				<span class="menu__text">Blog</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="https://zhiqiyu.github.io/about/">
				
				<span class="menu__text">About</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		
		</header><div class="content post__content clearfix">
			<p>Recently, during a discussion with a colleague about his CNN model architecture on remote sensing image fusion task, he mentioned something that was interesting. Specifically, in his network, he used FCN implementations <code>Keras.layers.Dense</code> and <code>torch.nn.Linear</code> in his code, the input to the FCN is a 2D image with many channels with size <code>(160, 160, channels)</code>. Traditionally, I think that to pass through a FCN layer, the neuron numbers of the first FCN layer in this case, should be <code>160 * 160 * channels</code>, which basically means to flat the volume to a 1D array and feed in a traditional neural network. Therefore, I argued that his network should be really hard to train because with such large number of neurons in a layer, the whole FCN should have millions of parameters. Just like the VGG, the parameters of its FCN layers are:</p>
<table>
<thead>
<tr>
<th style="text-align:left">layer #</th>
<th style="text-align:left">parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">7<em>7</em>512*4096 + 4096 = 102,764,544</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left">4096*4096 + 4096 = 16,781,312</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left">4096*1000 + 1000 = 4,097,000</td>
</tr>
<tr>
<td style="text-align:left"><strong>Total</strong></td>
<td style="text-align:left">approx. <strong>123.64M</strong></td>
</tr>
</tbody>
</table>
<p>However, my colleague told me that his FCN does not have such large number of parameters. Specifically, in his code, he used <code>Dense(channel#1)</code> and <code>Dense(channel#2)</code> instead of <code>Dense(160*160*channel#1)</code> and <code>Dense(160*160*channel#2)</code>. Therefore, his network only has <code>channel#1 * channel#2</code> parameters, which is signifiantly less than <code>160*160*160*160*channel#1 * channel#2</code>. This makes me wonder what dense layers are actually computing.</p>
<p>By digging around on the internet, I found a quote by Yan LeCuns:</p>
<blockquote>
<p>In Convolutional Nets, there is no such thing as &ldquo;fully-connected layers&rdquo;. There are only convolution layers with 1x1 convolution kernels and a full connection table.</p>
</blockquote>
<blockquote>
<p>It&rsquo;s a too-rarely-understood fact that ConvNets don&rsquo;t need to have a fixed-size input. You can train them on inputs that happen to produce a single output vector (with no spatial extent), and then apply them to larger images. Instead of a single output vector, you then get a spatial map of output vectors. Each vector sees input windows at different locations on the input.</p>
</blockquote>
<blockquote>
<p>In that scenario, the &ldquo;fully connected layers&rdquo; really act as 1x1 convolutions.</p>
</blockquote>
<p>This quote is not very explicit, but what LeCuns tries to say is that in CNN, if the input to the FCN is a volume instead of a vector, the FCN really acts as 1x1 convolutions, which only do convolutions in the channel dimension and reserve the spatial extent. But this is not true in the VGG case. In VGG, the input to the FCN is a <code>7*7*512</code> volume, what the first FCN layer does is actually a 7x7 convolution that shrink the volume to a 1x1 vector, and then do 1x1 convolution on the vector.</p>
<p>To further explain what the dense layer does in CNN, let&rsquo;s see an example in Keras:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
<span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Dense, Activation
model <span style="color:#f92672">=</span> Sequential()
model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">16</span>, input_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">2</span>)))
model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;relu&#39;</span>))
model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">4</span>))
model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;mean_squared_error&#39;</span>, optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;SGD&#39;</span>)
<span style="color:#66d9ef">print</span>(model<span style="color:#f92672">.</span>weights)
</code></pre></div><p>By running this example code, we can get the weights of the model as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">[<span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Variable <span style="color:#e6db74">&#39;dense_13/kernel:0&#39;</span> shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">16</span>) dtype<span style="color:#f92672">=</span>float32_ref<span style="color:#f92672">&gt;</span>,
 <span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Variable <span style="color:#e6db74">&#39;dense_13/bias:0&#39;</span> shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>,) dtype<span style="color:#f92672">=</span>float32_ref<span style="color:#f92672">&gt;</span>,
 <span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Variable <span style="color:#e6db74">&#39;dense_14/kernel:0&#39;</span> shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">4</span>) dtype<span style="color:#f92672">=</span>float32_ref<span style="color:#f92672">&gt;</span>,
 <span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Variable <span style="color:#e6db74">&#39;dense_14/bias:0&#39;</span> shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">4</span>,) dtype<span style="color:#f92672">=</span>float32_ref<span style="color:#f92672">&gt;</span>]
</code></pre></div><p>In this example, the input tensor with size <code>(3, 2)</code> is passed through a dense layer with 16 neurons, and then thorugh another dense layer with 4 neurons. In traditional neural networks, we can easily think that the first layer has <code>3 * 2 * 16 = 96</code> parameters as each neuron is connected to <code>3x2 = 6</code> inputs, and the next layer has <code>16 * 4 = 64</code> parameters. <strong>However</strong>, we can see that the printed weight matrix size of the first dense layer is <code>(2, 16)</code>, not <code>(2*3, 16)</code>.</p>
<p>Let&rsquo;s see another example:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
<span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Dense, Activation, Flatten
model <span style="color:#f92672">=</span> Sequential()
model<span style="color:#f92672">.</span>add(Flatten(input_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">2</span>)))  <span style="color:#75715e"># Flatten the input before feeding it into the dense layer</span>
model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">16</span>))
model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;relu&#39;</span>))
model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">4</span>))
model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;mean_squared_error&#39;</span>, optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;SGD&#39;</span>)
<span style="color:#66d9ef">print</span>(model<span style="color:#f92672">.</span>weights)
</code></pre></div><p>This code snippet prints out:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">[<span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Variable <span style="color:#e6db74">&#39;dense_15/kernel:0&#39;</span> shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">16</span>) dtype<span style="color:#f92672">=</span>float32_ref<span style="color:#f92672">&gt;</span>,
 <span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Variable <span style="color:#e6db74">&#39;dense_15/bias:0&#39;</span> shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>,) dtype<span style="color:#f92672">=</span>float32_ref<span style="color:#f92672">&gt;</span>,
 <span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Variable <span style="color:#e6db74">&#39;dense_16/kernel:0&#39;</span> shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">4</span>) dtype<span style="color:#f92672">=</span>float32_ref<span style="color:#f92672">&gt;</span>,
 <span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Variable <span style="color:#e6db74">&#39;dense_16/bias:0&#39;</span> shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">4</span>,) dtype<span style="color:#f92672">=</span>float32_ref<span style="color:#f92672">&gt;</span>]
</code></pre></div><p>There we can see that by flattening the input to a 1-D array before feeding it to the dense layers, the weight matrix of the first layer becomes <code>(6, 16)</code>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>How the FCN in CNN really do depends on the input shape:</p>
<ul>
<li>If the input is a 1-D vector, such as the output of the first VGG FCN layer <code>(1x1, 4096)</code>, the dense layers are the same as the hidden layers in traditional neural networks (multi-layer perceptron).</li>
<li>If the input rank is higher than 1, for example, an image volume, the FCN layer in CNN is actually doing similar things as a 1x1 convolution operation on each pixel slice.</li>
</ul>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="https://zhiqiyu.github.io/tags/deep-learning/" rel="tag">Deep Learning</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="https://zhiqiyu.github.io/tags/keras/" rel="tag">Keras</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Zhiqi Yu avatar" src="https://zhiqiyu.github.io/img/avatar.jpg" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Zhiqi Yu</span>
	</div>
	<div class="authorbox__description">
		Full stack developer, remote sensing researcher.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="https://zhiqiyu.github.io/post/dl-special-cert/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Deep Learning Specialization Certificate</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="https://zhiqiyu.github.io/post/landsat-sentinel-match/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Same-day Landsat-8 and Sentinel-2 Pair Generation on GEE</p>
		</a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "realm-z" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 Zhiqi Yu.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="https://zhiqiyu.github.io/js/menu.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>